{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa2ada3-1f4a-4690-af61-6f265b463aa5",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3027a-ec71-4ac9-bd41-34bb651b9a00",
   "metadata": {},
   "source": [
    "###### Importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d92b1557-5405-4f0f-af93-609956bcf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from newsapi import NewsApiClient\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b0325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09fe9818-aa18-4a34-b7b7-1a6b811d9fe9",
   "metadata": {},
   "source": [
    "#### 1. OBTAINING API KEY AND DOWNLOADING THE STOCK DATA AND NEWS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab07bac9-f1f2-4057-beb4-5eab56cfe9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining News API Key\n",
    "news_api_key = \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2b4a5d-a2be-48b7-8fb8-95bd630bdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Historical Stock Data\n",
    "start_date = \"2023-10-15\"\n",
    "end_date = \"2023-11-14\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428feba5-2088-4af2-a111-9a26b8a25f12",
   "metadata": {},
   "source": [
    "##### (NOTE : the accessible date is for the latest 30 days, so start_date and end_date must be adjusted according to the current date before running the code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c9981-f614-4bdf-b791-536afee87dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Downloading historical stock price data for Apple Inc. (AAPL)\n",
    "stock_data = yf.download(\"AAPL\", start=start_date, end=end_date)\n",
    "print((stock_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "259e4cac-bf02-4be0-9985-f74585db9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to make date a column\n",
    "stock_data.reset_index(inplace=True)\n",
    "stock_data.index = pd.to_datetime(stock_data.index)  # If Date is an index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc191e82-e418-47c9-9dd5-8f8cb66eab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_news(company, api_key, from_date, to_date):\n",
    "    newsapi = NewsApiClient(api_key=api_key)\n",
    "    headlines = newsapi.get_everything(\n",
    "        q=company,\n",
    "        from_param=from_date,\n",
    "        to=to_date,\n",
    "        language=\"en\",\n",
    "        sort_by=\"publishedAt\",\n",
    "    )\n",
    "    return headlines[\"articles\"]\n",
    "# Obtaining News API Key\n",
    "news_api_key = \"**\"\n",
    "# Ensure the Date column/index is in datetime format\n",
    "stock_data.index = pd.to_datetime(stock_data.index)  # If Date is an index\n",
    "# OR stock_data[\"Date\"] = pd.to_datetime(stock_data[\"Date\"])  # If Date is a column\n",
    "\n",
    "# Fetch news headlines for the given date range\n",
    "news_articles = []\n",
    "\n",
    "# If Date is in the index\n",
    "for date in stock_data.index:\n",
    "    date_str = date.strftime(\"%Y-%m-%d\")\n",
    "    news = fetch_news(\"Apple Inc.\", news_api_key, date_str, date_str)\n",
    "    news_articles.append({\"Date\": date, \"News\": news})\n",
    "\n",
    "# If Date is a column\n",
    "# for index, row in stock_data.iterrows():\n",
    "#     date_str = row[\"Date\"].strftime(\"%Y-%m-%d\")\n",
    "#     news = fetch_news(\"Apple Inc.\", news_api_key, date_str, date_str)\n",
    "#     news_articles.append({\"Date\": row[\"Date\"], \"News\": news})\n",
    "\n",
    "# Display results\n",
    "print(news_articles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb0261-41f7-474e-ae60-a76a4796615c",
   "metadata": {},
   "source": [
    "#### 2. DATA MERGING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439f504-eb05-40cb-b990-bf860fc63ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining stock data with news data\n",
    "merged_data = pd.merge(stock_data, pd.DataFrame(news_articles), on=\"Date\", how=\"left\")\n",
    "\n",
    "# Forward filling missing news data\n",
    "merged_data[\"News\"].fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405df41e-352a-4bbb-9bae-f1bfeb80fc09",
   "metadata": {},
   "source": [
    "#### 3. FEATURE EXTRACTION USING THE TEXTBLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a85ef-9567-430b-b926-caa6575efa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - Sentiment Analysis\n",
    "def analyze_sentiment(news_list):\n",
    "    # Perform sentiment analysis using TextBlob\n",
    "    sentiments = [TextBlob(news[\"title\"]).sentiment.polarity for news in news_list]\n",
    "    # Return the average sentiment polarity for all news articles\n",
    "    return np.mean(sentiments)\n",
    "\n",
    "# Appling sentiment analysis to the News column and create a new feature 'Sentiment'\n",
    "merged_data['Sentiment'] = merged_data['News'].apply(lambda x: analyze_sentiment(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Display the updated data with the new 'Sentiment' feature\n",
    "print(merged_data[['Date', 'Close', 'News', 'Sentiment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59d76f-90e3-4ede-8f4b-c0be3f0c53d5",
   "metadata": {},
   "source": [
    "#### 4. SPLITTING DATASET INTO TRAINING AND TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d53654cf-2a20-4fcf-86aa-c392a18877d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features (including the new 'Sentiment' feature) and target variable\n",
    "features = merged_data[[\"Open\", \"High\", \"Low\", \"Volume\", \"Sentiment\"]]\n",
    "target = merged_data[\"Close\"]\n",
    "\n",
    "# Spliting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b63107-08ac-4a4b-9e40-65a66dcd26d3",
   "metadata": {},
   "source": [
    "#### 5. MODEL BUILDING (with rbf kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79d36660-1e45-487b-b240-52fbdfcf4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building - SVR with 'rbf' kernel\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb98ef7-4341-4238-accd-5de1710dc013",
   "metadata": {},
   "source": [
    "#### 6. MODEL TRAINING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "401f57e9-3e42-4f7f-a79a-5971e92add1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "# Training the SVR model on the training data\n",
    "svr_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the test set for the next 30 days\n",
    "future_dates = pd.date_range(end=merged_data['Date'].max(), periods=30, freq='B')[1:]  # Generate next 30 business days\n",
    "future_features = pd.DataFrame(index=future_dates, columns=features.columns)\n",
    "future_features['Sentiment'] = 0.5  # You can update this with actual sentiment analysis on future news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db93572-feb5-421e-a741-433f2be35313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values in future_features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "future_features_imputed = imputer.fit_transform(future_features)\n",
    "\n",
    "# Using only the first feature\n",
    "single_feature = future_features_imputed[:, 0].reshape(-1, 1)\n",
    "\n",
    "# Standardizing the feature\n",
    "scaler = StandardScaler()\n",
    "single_feature_scaled = scaler.fit_transform(single_feature)\n",
    "\n",
    "# Spliting the data into training and testing sets\n",
    "# Assuming you have X_train, X_test, y_train, y_test\n",
    "\n",
    "# Training a new SVR model\n",
    "svr_rbf_single_feature = SVR(kernel='rbf')\n",
    "svr_rbf_single_feature.fit(X_train_scaled[:, :1], y_train)  # Assuming only the first feature is used\n",
    "\n",
    "# Make predictions for the next 30 days\n",
    "future_predictions = svr_rbf_single_feature.predict(single_feature_scaled)\n",
    "\n",
    "# Evaluating the model's performance on the test set\n",
    "y_pred_test = svr_rbf_single_feature.predict(X_test_scaled[:, :1])\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R^2): {r2}\")\n",
    "\n",
    "# Saving the model as a pickle file\n",
    "model_filename = \"svr_model.pkl\"\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(svr_rbf, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
